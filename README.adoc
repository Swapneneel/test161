= `test161`: A Testing Tool for OS/161

`test161` is a command line tool for automated testing of
http://os161.eecs.harvard.edu[OS/161] instructional operating system kernels
that run inside the `sys161` (System/161)
https://en.wikipedia.org/wiki/R3000[MIPS R3000] simulator. You are probably
not interested in `test161` unless you are a student taking or an instructor
teaching a course that uses OS/161.

== Installing Go

Many Linux distributions package fairly out-of-date versions of Go. Instead,
we encourage you to install the https://github.com/moovweb/gvm[Go Version Manager (GVM)]:

[source,bash]
----
sudo apt-get install -y curl bison # Install requirement
bash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
source $HOME/.gvm/scripts/gvm
----

At this point you are ready to start using GVM. We are currently building and
testing `test161` with Go version `go1.6beta2`. However, because the Go
compiler is now written in Go, installing versions of Go past 1.5 require
install Go version 1.4 first.

[source,bash]
----
gvm install go1.4
gvm use 1.4
gvm install go1.6beta2
gvm use 1.6beta2
----

Once you have Go installed you should set your `GOPATH` and `PATH` environment
variables appropriately as https://golang.org/doc/code.html#GOPATH[described
here.] For students using the https://www.ops-class.org[`ops-class.org`]
https://github.com/ops-class/vagrant[Vagrant virtual machine], this should be
safe:

[source,bash]
----
export GOPATH=$HOME/go
export PATH=$PATH:$GOPATH/bin
----

Add these settings to your `.bashrc` or equivalent file.

== Installing `test161`

Once you have Go installed, upgrading or installing `test161` is simple:

[source,bash]
----
go get -u github.com/ops-class/test161/
go install github.com/ops-class/test161/test161
----

== Configuration

== Usage

`test161` requires a set of arguments. The following can be provided either
on the command line or in a YAML configuration file:

* `root:` or `--root`: the location of a directory containing the kernel
binary to test and any associated executables that are required, probably
`~/root/` or `~/os161/root` depending on how you have configured your OS/161
source tree
* `tests:` or `--tests`: a list of directories containing testing scripts.

== Requirements

* `sys161` and `disk161` in the path.

== Default Settings

....
conf:
  cpus: 4
  ram: 1M
  disk1:
    sectors: min(2 * ram, 8000) # 8000 is a minimum due to a current sys161 bug
    rpm: 7200
    nodoom: true
  disk2: # disabled by default, but uses these defaults if configured
    sectors: min(2 * ram, 8000)
    rpm: 7200
    nodoom: false
  random: seed=random # random number generated at configuration time
monitor:
  enabled: true
  intervals: 10
  kernel:
    min: 0.001
    max: 0.99
  user:
    min: 0.0001
    max: 1.0
  timeouts:
    prompt: 300
    progress: 60
....

== Features

=== Testfile Syntactic Sugar

A line starting with `$` will be run in the shell and start the shell as
needed. Lines not starting with `$` are run from the kernel prompt and get
there if necessary by exiting the shell. `sys161` shuts down cleanly without
requiring the test manually exit the shell and kernel, as needed.

So this test:
....
$ /bin/true
....

Expands to:
....
s
/bin/true
exit
q
....

*Note that commands run in the shell _must_ be prefixed with `$`.* Otherwise
`test161` will consider them a kernel command and exit the shell before
running them. For example:

This test is probably not what you want:
....
s
/bin/true
....

Because it will expand to:
....
s
exit
/bin/true # not a kernel command
....

But this is so much simpler, right?
....
$ /bin/true
....

=== Progress Tracking Using `stat161` Output

`test161` uses the collected `stat161` output produced by the running kernel to
detect deadlocks, livelocks, and other forms of stalls. We do this using
several different strategies:

. *Progress and prompt timeouts.* Testfiles can configure both progress
(`monitorconf.timeouts.progress`) and prompt (`monitorconf.timeouts.prompt`)
timeouts. The former is used to kill the test if no output has appeared, while
the latter is passed to `expect` and used to kill the test of the prompt is
delayed. Ideally OS/161 tests should produce some output while they run to
help keep the progress timeout from firing, but the other progress tracking
strategies described below should also help.
. *User and kernel maximum and minimum cycles.* `test161` maintains a buffer
of statistics over a configurable number of `stat161` intervals. Limits on the
minimum and maximum number of kernel and user cycles (expressed as fractions)
over this buffer can help detect deadlocks (minimum) and livelocks (maximum).
User limits are only applied when running in userspace.
.  Note that `test161`
also checks to ensure that there are no user cycles generated when we are
running in kernel mode, which could be caused by a hung progress.

== TODOs

=== Nits

* Handle missing newline correctly. Test with shll for lossy shell support.
* Configuration sanity checks
* sys161 version checks

=== Running multiple tests and dependencies

Support for loading a bunch of tests from a directory and running multiple
tests concurrently, probably identified by a tag. (You might want to look at
this parallel walk library: github.com/MichaelTJones/walk)

For test dependency traking my idea is to have all tests start in parallel in
multiple goroutines but then wait on a channel until all of their
dependencies are met (or one fails, in which case the test will abort). To
control concurrency, they should next wait on a separate channel for a
message from a concurrency manager that can limit the number of `sys161`
instances executing in parallel.

=== Multiple output strategies

We want to support printing to the screen (not the JSON, but output that
looks like what you'd see in the terminal) and saving JSON output to a
MongoDB instance for later grading.

=== Primitive success or failure tracking

This isn't grading, which is more
fine-grained, just a sense of whether the test(s) completely successfully and
didn't panic. I'm working on standardizing the OS/161 test output to make
this easier so that every test prints a SUCCESS or FAILURE message on exit,
but we still need to grab panics.

commands.go has the building blocks for determining this. Expected output is
specified using golang templates.  Also, random inputs can be generated in
this way as well. Some things that still need to be done:

* Master commands template yaml file, which will get updated as the output
is fixed in os161
* External output references (i.e. triplehuge referencing huge)
* Integrating this with Tests and, eventually, submissions.

=== Support for GDB backtraces on error

It should be possible to automate the process of hooking up a debugger and
running BT on panics.


=== Targets/Submissions

This needs to be fully designed.  Some considerations:

* Multiple target types, e.g. assignments, performance
* Grading
* Integration with TestGroups (which work)
* Output format
* Submission metadata
* Test specification
* Argument overriding (see commands.go)
* Short-circuit setting - when to stop the test?  when to skip dependencies?

=== Security

The os161 side is in working condition, though we need still need to modify
userspace binaries and add secprintf to userspace.  In test161, we need to
verify output lines when we see the secure 4-tuple. Still to do:

* Key generation
* Overlay file copying
* Key substitution
* Key verification

=== Client & Server Binaries

* Client Local test runner
* Client sumbission
* Server daemon
* Server stats?
