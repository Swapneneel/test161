= `test161`: A Testing Tool for OS/161

`test161` is a command line tool for automated testing of
http://os161.eecs.harvard.edu[OS/161] instructional operating system kernels
that run inside the `sys161` (System/161)
https://en.wikipedia.org/wiki/R3000[MIPS R3000] simulator. You are probably
not interested in `test161` unless you are a student taking or an instructor
teaching a course that uses OS/161.

== Installing Go

Many Linux distributions package fairly out-of-date versions of Go. Instead,
we encourage you to install the https://github.com/moovweb/gvm[Go Version Manager (GVM)]:

[source,bash]
----
sudo apt-get install -y curl bison # Install requirement
bash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
source $HOME/.gvm/scripts/gvm
----

At this point you are ready to start using GVM. We are currently building and
testing `test161` with Go version `go1.6beta2`. However, because the Go
compiler is now written in Go, installing versions of Go past 1.5 require
install Go version 1.4 first.

[source,bash]
----
gvm install go1.4
gvm use 1.4
gvm install go1.6beta2
gvm use 1.6beta2
----

=== `GOPATH`

Note that `gvm` will set your `GOPATH` and `PATH` variables properly to allow
you to run Go binaries that you install. However, if you are interested in
writing Go code you should set a more accessible `GOPATH` as described as https://golang.org/doc/code.html#GOPATH[described
here.]

== Installing `test161`

Once you have Go installed, upgrading or installing `test161` is simple:

[source,bash]
----
go get -u github.com/ops-class/test161/
go install github.com/ops-class/test161/test161
----

== Configuration

In order to run `test161`, it needs to know about which <<tests>>, 
<<targets>>, and <<commands>> it can run, and what to expect from  each command.
Additionally, `test161` needs to know where to find your root directory for
testing and your repository for submission. This information is specified in your
`.test161.conf` file, which can be located in your `$HOME` directory, or whichever
directory you plan to run `test161` in. If you run `test161 run` without a config
file set up, an example will be displayed on screen.  You can redirect this output
to `.test161.conf` and edit it accordingly.

[source,bash]
----
test161 run > ~/.test161.conf
vim ~/.test161.conf
----

== Usage

=== Running Tests

To run a tests, group of tests, or target, use the `test161 run <names>` sub-command.
Here, names can be a single target, a list of tests, or a list of <<tags>>.footnote:[In the case
that tag and target names conflict, specify `-tag` if you mean tag.] For test files,
<names> is a list of http://www.linuxjournal.com/content/globstar-new-bash-globbing-option [globstar]
style file names.  The following are all valid commands:

[source,bash]
----
test161 run sync/*.t         # Run all tests in the tests/sync
test161 run **/l*.t          # Run all tests in all sub-directories beginning with 'l'
test161 run syncprobs/sp*.t  # Run the syncprobs
test161 run sync/lt1.t       # Run lock test 1
test161 run locks            # Run all lock tests (tests tagged with 'locks')
test161 run asst1            # Run the asst1 target
----

==== Command Line Flags
There are several command line flags that can be specified to customize how `test161` runs tests.

* `-dry-run` (`-r`): Show the tests that would be run, but don't run them.
* `-sequential` (`-s`): By default the output of all tests are interleaved, which can be hard to debug.
Specify this option to run tests one at a time.
* `-dependencies` (`-d`): Run the given tests and their dependencies. In test files, you can specify a
test's dependencies, and the test will be skipped if the dependency fails.
* `-verbose` (`-v`): There are 3 levels of output: `loud` (default), `quiet` (no test output), and `whisper` (only final summary, no
per test status).

== Requirements

* `sys161` and `disk161` in the path.

== Default Settings

....
conf:
  cpus: 4
  ram: 1M
  disk1:
    sectors: min(2 * ram, 8000) # 8000 is a minimum due to a current sys161 bug
    rpm: 7200
    nodoom: true
  disk2: # disabled by default, but uses these defaults if configured
    sectors: min(2 * ram, 8000)
    rpm: 7200
    nodoom: false
  random: seed=random # random number generated at configuration time
monitor:
  enabled: true
  intervals: 10
  kernel:
    min: 0.001
    max: 0.99
  user:
    min: 0.0001
    max: 1.0
  timeouts:
    prompt: 300
    progress: 60
....

== Commands, Tests, and Targets

=== [[commands]]Commands

The basic unit in `test161` is a command. such as `lt1` for running Lock Test 1,
or `sp1` to run the whalemating test.  Information about what to
expect when running these commands, as well as what input/ouput they expect
 is specified in the `commands/` directory in your test161 root directory.
All .tc (test command) file in this directory will be loaded and commands must
only be specified once.

=== [[tests]]Tests

Test files (`*.t`) are located in the `tests/` directory in your test161 root
directory. This directory can contain subdirectories to help organize tests.
Each test consists of one or more commands, and each test can have its own
`sys161` configuration.  Tests are run in their own sandboxed envrionment, 
but commands within the test are executed within the same `sys161` session.
Some tests will consist of multiple commands, and such tests are designed to
stress test your system.

=== [[targets]]Targets

Target files (`*.tt`) are located in the `targets/` directory in your test161 root
directory. Targets specify which tests are run for each assignment, and
how the scoring is distributed. When you `test161 submit` your assignments, you will
specify which target to submit to.

== Features

=== Testfile Syntactic Sugar

A line starting with `$` will be run in the shell and start the shell as
needed. Lines not starting with `$` are run from the kernel prompt and get
there if necessary by exiting the shell. `sys161` shuts down cleanly without
requiring the test manually exit the shell and kernel, as needed.

So this test:
....
$ /bin/true
....

Expands to:
....
s
/bin/true
exit
q
....

*Note that commands run in the shell _must_ be prefixed with `$`.* Otherwise
`test161` will consider them a kernel command and exit the shell before
running them. For example:

This test is probably not what you want:
....
s
/bin/true
....

Because it will expand to:
....
s
exit
/bin/true # not a kernel command
....

But this is so much simpler, right?
....
$ /bin/true
....

=== [[tags]]Test Tags
Optionally, tests can have one or more tags. `test161` can be invoked to run these tests
as a group with `test161 run <tag>`.

=== Progress Tracking Using `stat161` Output

`test161` uses the collected `stat161` output produced by the running kernel to
detect deadlocks, livelocks, and other forms of stalls. We do this using
several different strategies:

. *Progress and prompt timeouts.* Testfiles can configure both progress
(`monitorconf.timeouts.progress`) and prompt (`monitorconf.timeouts.prompt`)
timeouts. The former is used to kill the test if no output has appeared, while
the latter is passed to `expect` and used to kill the test of the prompt is
delayed. Ideally OS/161 tests should produce some output while they run to
help keep the progress timeout from firing, but the other progress tracking
strategies described below should also help.
. *User and kernel maximum and minimum cycles.* `test161` maintains a buffer
of statistics over a configurable number of `stat161` intervals. Limits on the
minimum and maximum number of kernel and user cycles (expressed as fractions)
over this buffer can help detect deadlocks (minimum) and livelocks (maximum).
User limits are only applied when running in userspace.
.  Note that `test161`
also checks to ensure that there are no user cycles generated when we are
running in kernel mode, which could be caused by a hung progress.


=== Running multiple tests and dependencies

=== Correctness vs. Grading

=== Multiple output strategies

`test161` supports different output strategies through its PersistenceManager
interface. Each TestEnvironment as a PersistenceManager which receives
callbacks when events happen, like when scores changes, status change, or when
output lines are added. This allows multiple implementations to handle output
as they wish. The test161 client utility implements the interface through
its ConsolePersistence type, which writes all input to stdout. The server uses
a MongoPersistence type which outputs JSON data to our mongo backend server.


== TODOs

=== Nits

* Handle missing newline correctly. Test with shll for lossy shell support.
* Configuration sanity checks
* sys161 version checks
* Correctly identify lines in interleaved output.
* Tracking dependencies should be the default and ignoring them the command
line option.
* Add ways to print all tests and groups.
* Set the exit code to indicate whether all tests passed.
* Order the test output in some meaningful way, probably by depth in the
dependency graph. (That way all skipped tests should be shown last.)

=== Environment inference

It would be great if we could not require the `.test161.conf` file in certain
cases, particularly for local testing. For example, if I'm in my source
directory I should be able to find the `test161` files and determine my `root`
directory by interpreting `defs.mk`. If I'm in my root directory that's a bit
trickier, although perhaps eventually we can have the build process stick a
symlink in the root dir back to the sources that create it for that purpose.
(You could also create a symlink from `/src/root` to the root dir when you
compile.)

=== Configuration override

It would be great if `test161 run boot.t --sys161-cpus=1` worked properly. I
think that there is a library for this.

=== Support for GDB backtraces on error

It should be possible to automate the process of hooking up a debugger and
running BT on panics.

=== Security

The os161 side is in working condition, though we need still need to modify
userspace binaries and add secprintf to userspace.  In test161, we currently
verify output lines when we see the secure 4-tuple, but the keymap still
needs to be generated during the build. Still to do:

* Key generation
* Overlay file copying
* Key substitution
* Check for unique salt values during validation

=== Server Binary
* Server stats API
